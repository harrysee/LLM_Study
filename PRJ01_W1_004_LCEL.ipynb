{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cd25bfb",
      "metadata": {},
      "source": [
        "# LangChain LCEL\n",
        "\n",
        "### **학습 목표:** LangChain의 LCEL을 사용하여 LLM 체인을 구성한다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2217fa83",
      "metadata": {},
      "source": [
        "## LCEL(LangChain Expression Language) \n",
        "\n",
        "- **LCEL**은 `|` 연산자를 사용해 컴포넌트들을 순차적으로 연결하는 선언적 체이닝을 지원합니다\n",
        "\n",
        "- **재사용성**이 높아 정의된 체인을 다른 체인의 컴포넌트로 활용할 수 있습니다\n",
        "\n",
        "- **다양한 실행 방식**(.invoke(), .batch(), .stream(), .astream())으로 동기/비동기 처리가 가능합니다\n",
        "\n",
        "- **배치 처리**시 자동 최적화를 통해 효율적인 작업 수행이 가능합니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd9328",
      "metadata": {
        "id": "8bfd9328"
      },
      "source": [
        "### 1. 환경 설정\n",
        "\n",
        "- langsmith 가입 필요 (https://www.langchain.com/langsmith)\n",
        "- 부분 무료"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ac3ddb",
      "metadata": {
        "id": "15ac3ddb"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
        "import os\n",
        "print(os.getenv('LANGCHAIN_TRACING'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129b8eee",
      "metadata": {
        "id": "129b8eee"
      },
      "source": [
        "### 2. LCEL  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68074eb8",
      "metadata": {
        "id": "68074eb8"
      },
      "source": [
        "#### 1) **Prompt + LLM**\n",
        "\n",
        "* 기본 구조: `Prompt | LLM` 형태로, 파이프(|) 연산자를 사용해 프롬프트와 LLM을 순차적으로 연결합니다.\n",
        "\n",
        "* 데이터 흐름: 사용자 입력이 Prompt 템플릿을 통해 처리된 후, LLM에 전달되어 최종 응답이 생성됩니다.\n",
        "\n",
        "* 실행 순서: 파이프라인은 왼쪽에서 오른쪽으로 순차적으로 실행되며, 각 컴포넌트의 출력이 다음 컴포넌트의 입력으로 전달됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3722db67",
      "metadata": {
        "id": "3722db67"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\", \n",
        "    temperature=0.3\n",
        "    )\n",
        "\n",
        "# 모델에 프롬프트를 입력\n",
        "response = llm.invoke(\"탄소의 원자 번호는 무엇인가요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e87eef4",
      "metadata": {
        "id": "9e87eef4"
      },
      "outputs": [],
      "source": [
        "# 응답 객체 확인\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ce51f7",
      "metadata": {
        "id": "47ce51f7"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 텍스트를 확인\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552cd7af",
      "metadata": {
        "id": "552cd7af"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 메타데이터를 확인\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0113cf90",
      "metadata": {
        "id": "0113cf90"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 문자열 정의\n",
        "template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 템플릿 사용 예시\n",
        "formatted_prompt = prompt.format(\n",
        "    topic=\"인공지능\",\n",
        "    question=\"딥러닝과 머신러닝의 주요 차이점은 무엇인가요?\"\n",
        ")\n",
        "\n",
        "print(\"템플릿 변수:\")\n",
        "print(f\"- 필수 변수: {prompt.input_variables}\")\n",
        "print(\"\\n생성된 프롬프트:\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b245d7",
      "metadata": {
        "id": "25b245d7"
      },
      "outputs": [],
      "source": [
        "# prompt 객체의 템플릿을 확인\n",
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c801f727",
      "metadata": {
        "id": "c801f727"
      },
      "outputs": [],
      "source": [
        "# chain을 구성\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53e9def",
      "metadata": {
        "id": "b53e9def"
      },
      "outputs": [],
      "source": [
        "# chain 객체 확인\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4f916f",
      "metadata": {
        "id": "6d4f916f"
      },
      "outputs": [],
      "source": [
        "# chain 객체의 입력 스키마를 확인\n",
        "chain.input_schema.model_json_schema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6015e000",
      "metadata": {
        "id": "6015e000"
      },
      "outputs": [],
      "source": [
        "# chain 실행\n",
        "response = chain.invoke( \n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa75f9ee",
      "metadata": {
        "id": "fa75f9ee"
      },
      "outputs": [],
      "source": [
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0a3843",
      "metadata": {
        "id": "fb0a3843"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 텍스트를 출력\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c5710c",
      "metadata": {
        "id": "c6c5710c"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 메타데이터를 출력\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983d4157",
      "metadata": {
        "id": "983d4157"
      },
      "source": [
        "#### **2) Prompt + LLM + Output Parser**\n",
        "\n",
        "* 데이터 파이프라인: `Prompt | LLM | OutputParser` 형태로 구성되어 LLM의 출력을 구조화된 형식으로 변환합니다.\n",
        "\n",
        "* Parser 종류: JSON, XML 등 다양한 형식의 파서를 지원하여 LLM 출력을 원하는 데이터 구조로 변환할 수 있습니다.\n",
        "\n",
        "* 유효성 검증: Parser가 출력 형식을 검증하여 잘못된 형식의 응답을 필터링하고 안정적인 데이터 처리를 보장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6b7607",
      "metadata": {
        "id": "7e6b7607"
      },
      "outputs": [],
      "source": [
        "### 문자열 출력 파서 \n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서를 생성\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 출력 파서를 실행\n",
        "output_parser.invoke(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158608d9",
      "metadata": {
        "id": "158608d9"
      },
      "outputs": [],
      "source": [
        "# 출력 파서를 chain에 추가\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain을 실행\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e95ba99",
      "metadata": {
        "id": "1e95ba99"
      },
      "outputs": [],
      "source": [
        "# input_schema (chain)\n",
        "chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0d6997",
      "metadata": {
        "id": "ba0d6997"
      },
      "outputs": [],
      "source": [
        "# input_schema (prompt)\n",
        "prompt.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4456bde9",
      "metadata": {
        "id": "4456bde9"
      },
      "source": [
        "### 3. Runnable\n",
        "\n",
        "* 실행 인터페이스: 모든 LangChain 컴포넌트는 Runnable 인터페이스를 구현하여 일관된 방식으로 실행됩니다.\n",
        "\n",
        "* 실행 메서드: `.invoke()`, `.batch()`, `.stream()`, `.astream()` 등 다양한 실행 방식을 제공합니다.\n",
        "\n",
        "* 호환성: 모든 Runnable 컴포넌트는 파이프(|) 연산자를 통해 연결 가능하며, 재사용이 용이합니다.\n",
        "\n",
        "* Runnable의 주요 유형:\n",
        "\n",
        "    * `RunnableSequence`: 여러 Runnable을 순차적으로 실행\n",
        "    * `RunnablePassthrough`: 입력을 그대로 다음 단계로 전달    \n",
        "    * `RunnableParallel`: 여러 Runnable을 병렬로 실행\n",
        "    * `RunnableLambda`: 파이썬 함수를 Runnable로 래핑하여 체인에서 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d0cfd",
      "metadata": {},
      "source": [
        "#### 1) **RunnableSequence**\n",
        "\n",
        "- **RunnableSequence**는 컴포넌트들을 연결하여 순차적으로 데이터를 처리하는 체인입니다\n",
        "\n",
        "- `|` 연산자로 연결된 각 단계의 **출력이 다음 단계의 입력**으로 전달됩니다\n",
        "\n",
        "- **다양한 실행 방식**(동기/비동기, 배치/스트리밍)을 지원합니다\n",
        "\n",
        "- LLM 체인, 데이터 파이프라인, 자동화된 작업 등 **다단계 처리**에 활용됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7c9cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# 컴포넌트 정의\n",
        "prompt = PromptTemplate.from_template(\"'{text}'를 영어로 번역해주세요. 번역된 문장만을 출력해주세요.\")\n",
        "translator = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# RunnableSequence 생성 - 함수 사용 \n",
        "translation_chain = RunnableSequence(\n",
        "    first=prompt,\n",
        "    middle=[translator],   # 리스트로 전달하는 점에 주의\n",
        "    last=output_parser\n",
        ")\n",
        "\n",
        "# RunnableSequence 생성 - 연산자 사용\n",
        "# translation_chain = prompt | translator | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5ff8cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 동기 실행\n",
        "result = translation_chain.invoke({\"text\": \"안녕하세요\"})\n",
        "print(result)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a93db3",
      "metadata": {},
      "source": [
        "**[비동기 처리의 주요 이점]**\n",
        "\n",
        "* 응답성: I/O 작업 중 다른 작업 수행이 가능하여 시스템 전체 응답성 향상\n",
        "\n",
        "* 확장성: 여러 요청을 동시에 처리할 수 있어 처리량 증가\n",
        "\n",
        "* 리소스 활용: CPU와 메모리를 효율적으로 활용하여 성능 최적화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7d2ad50f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# Jupyter에서 비동기 실행을 위한 설정\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 비동기 실행 함수를 정의\n",
        "async def run():\n",
        "    result = await translation_chain.ainvoke({\"text\": \"감사합니다\"})\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01afbeb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#  비동기 실행 함수를 호출\n",
        "await run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb7e8bf",
      "metadata": {},
      "source": [
        "#### 2) **RunnableParallel**\n",
        "\n",
        "- **RunnableParallel**은 여러 컴포넌트를 딕셔너리 형태로 구성해 **동시 실행**합니다\n",
        "\n",
        "- 동일한 입력이 모든 병렬 컴포넌트에 전달되며, 결과는 **키-값 쌍**으로 반환됩니다\n",
        "\n",
        "- **데이터 변환**과 **파이프라인 구성**에 특화되어 있으며, 출력 형식을 다음 단계에 맞게 조정할 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625baaa0",
      "metadata": {},
      "source": [
        "`(1) 질문 분석 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f19926e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "분류 결과: 답변: 화학(Chemistry)\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 질문 템플릿 정의\n",
        "question_template = \"\"\"\n",
        "다음 카테고리 중 하나로 입력을 분류하세요:\n",
        "- 화학(Chemistry)\n",
        "- 물리(Physics)\n",
        "- 생물(Biology)\n",
        "\n",
        "# 예시:\n",
        "입력: 사람의 염색체는 모두 몇개가 있나요?\n",
        "답변: 생물(Biology)\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "question_prompt = ChatPromptTemplate.from_template(question_template)\n",
        "\n",
        "# 모델 설정\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\", \n",
        "    temperature=0.3\n",
        "    )\n",
        "\n",
        "# 체인 구성\n",
        "question_chain = question_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행\n",
        "result = question_chain.invoke({\"question\": \"탄소의 원자 번호는 무엇인가요?\"})\n",
        "print(f\"분류 결과: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa45a8",
      "metadata": {},
      "source": [
        "`(2) 언어 감지 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f5ce2883",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력: What is the atomic number of carbon?\n",
            "분류 결과: English\n",
            "\n",
            "입력: 탄소의 원자 번호는 무엇인가요?\n",
            "분류 결과: 한국어(Korean)\n",
            "\n",
            "입력: ¿Cuál es el número atómico del carbono?\n",
            "분류 결과: 답변: Others\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 질문에 사용된 언어를 구분하는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 언어 분류 템플릿 정의\n",
        "language_template = \"\"\"\n",
        "입력된 텍스트의 언어를 다음 카테고리 중 하나로 분류하세요:\n",
        "- 영어(English)\n",
        "- 한국어(Korean)\n",
        "- 기타(Others)\n",
        "\n",
        "# 예시:\n",
        "입력: How many protons are in a carbon atom?\n",
        "답변: English\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "language_prompt = ChatPromptTemplate.from_template(language_template)\n",
        "\n",
        "# 체인 구성\n",
        "language_chain = language_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "examples = [\n",
        "    \"What is the atomic number of carbon?\",\n",
        "    \"탄소의 원자 번호는 무엇인가요?\",\n",
        "    \"¿Cuál es el número atómico del carbono?\"\n",
        "]\n",
        "\n",
        "for example in examples:\n",
        "    result = language_chain.invoke({\"question\": example})\n",
        "    print(f\"입력: {example}\")\n",
        "    print(f\"분류 결과: {result}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c273a56e",
      "metadata": {},
      "source": [
        "`(3) RunnableParallel을 사용한 병렬 실행 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bf0b47c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "처리 결과:\n",
            "답변: 탄소의 원자 번호는 6입니다.\n"
          ]
        }
      ],
      "source": [
        "# 질문과 관련된 분야를 찾아서 질문에 대한 답변을 생성하는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# 답변 템플릿 정의\n",
        "answer_template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 질문에 {language}로 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 및 체인 구성\n",
        "answer_prompt = ChatPromptTemplate.from_template(answer_template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 병렬 처리 체인 구성\n",
        "answer_chain = RunnableParallel({\n",
        "    \"topic\": question_chain,            # 주제 분류 체인\n",
        "    \"language\": language_chain,         # 언어 감지 체인\n",
        "    \"question\": itemgetter(\"question\")  # 원본 질문 추출\n",
        "}) | answer_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "result = answer_chain.invoke({\n",
        "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "})\n",
        "\n",
        "print(\"처리 결과:\")\n",
        "print(f\"답변: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ddb27f",
      "metadata": {},
      "source": [
        "#### 3) **RunnablePassthrough**\n",
        "\n",
        "- **RunnablePassthrough**는 입력값을 그대로 전달하여 원본 데이터를 보존합니다\n",
        "\n",
        "- **RunnableParallel**과 함께 사용되어 입력 데이터를 새로운 키로 매핑할 수 있습니다\n",
        "\n",
        "- **투명한 데이터 흐름**으로 파이프라인 디버깅과 구성이 용이합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "11de1469",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': {'query': '탄소의 원자 번호는 6입니다.'}, 'modified': 6}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import re\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x[\"query\"]).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke({\"query\": '탄소의 원자 번호는 6입니다.'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346a12dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke('탄소의 원자 번호는 6입니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e888c65",
      "metadata": {
        "id": "2e888c65"
      },
      "source": [
        "#### 4) **RunnableLambda**\n",
        "\n",
        "- **RunnableLambda**는 일반 함수를 Runnable 객체로 변환하는 래퍼 컴포넌트입니다\n",
        "\n",
        "- 체인에 **커스텀 로직**을 쉽게 통합할 수 있어 데이터 전처리, 후처리에 유용합니다\n",
        "\n",
        "- `|` 연산자로 다른 컴포넌트들과 연결해 **복잡한 처리 흐름**을 구성할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f7f8d92f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "# 텍스트에서 숫자를 추출하는 함수\n",
        "def extract_number(query):\n",
        "    return int(re.search(r'\\d+', query).group())\n",
        "\n",
        "# RunnablePassthrough로 입력을 그대로 전달하고, RunnableLambda로 숫자 추출 함수 실행\n",
        "runnable = RunnablePassthrough() | RunnableLambda(extract_number)\n",
        "\n",
        "# 입력 텍스트에서 6을 추출\n",
        "result = runnable.invoke('탄소의 원자 번호는 6입니다.')\n",
        "print(result)  # 출력: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6704894c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 데이터 전처리 함수 정의\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\" 입력 텍스트를 소문자로 변환하고 양쪽 공백을 제거합니다. \"\"\"\n",
        "    return text.strip().lower()\n",
        "\n",
        "# 후처리 함수 정의\n",
        "def postprocess_response(response: str) -> dict:\n",
        "    \"\"\" 응답 텍스트를 대문자로 변환하고 길이를 계산합니다. \"\"\"\n",
        "    response_text = response.content\n",
        "    return {\n",
        "        \"processed_response\": response_text.upper(),\n",
        "        \"length\": len(response_text)\n",
        "    }\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = ChatPromptTemplate.from_template(\"다음 주제에 대해 영어 한 문장으로 설명해주세요: {topic}\")\n",
        "\n",
        "# 처리 파이프라인 구성\n",
        "chain = (\n",
        "    RunnableLambda(preprocess_text) |  # 입력 전처리\n",
        "    prompt |                           # 프롬프트 포맷팅\n",
        "    llm |                              # LLM 추론\n",
        "    RunnableLambda(postprocess_response)  # 출력 후처리\n",
        ")\n",
        "\n",
        "# 체인 실행\n",
        "result = chain.invoke(\"인공지능\")\n",
        "print(f\"처리된 응답: {result['processed_response']}\")\n",
        "print(f\"응답 길이: {result['length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d46b8",
      "metadata": {},
      "source": [
        "# [실습]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5b260a",
      "metadata": {},
      "source": [
        "- **다음과 같은 요구사항을 LCEL로 구현합니다**\n",
        "   1. 사용자 입력을 받아 요약하기\n",
        "   2. 요약된 내용을 기반으로 감정 분석하기 (긍정, 부정, 중립)\n",
        "   3. 요약된 문장과 감정 분석 결과를 출력하기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e424f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "summarize_prompt = None\n",
        "\n",
        "sentiment_prompt = None\n",
        "\n",
        "# 문자열 출력 파서\n",
        "output_parser = None\n",
        "\n",
        "# 체인 구성\n",
        "model = None\n",
        "\n",
        "# 요약 체인\n",
        "summarize_chain = None\n",
        "\n",
        "# 감정 분석 체인\n",
        "sentiment_chain = None\n",
        "\n",
        "# 전체 체인\n",
        "chain = None\n",
        "\n",
        "# 사용 예시\n",
        "text = \"\"\"오늘 시험에서 만점을 받았다. \n",
        "시험 준비를 열심히 해서 결과가 좋았다.\n",
        "시험이 끝난 후 친구들과 함께 축하 파티를 열었다.\n",
        "시험이 끝나고 나니 마음이 홀가분하다.\n",
        "시험 준비를 하면서 힘든 순간도 있었지만,\n",
        "그런 순간들이 나를 더 강하게 만들어 주었다.\n",
        "정말 기쁘고 노력한 보람이 있었다!\"\"\"\n",
        "result = None\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 모델 & 파서\n",
        "llm = ChatOpenAI()\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# 1. 요약 프롬프트\n",
        "summarize_prompt = PromptTemplate.from_template(\"\"\"\n",
        "다음 글을 한 문장으로 요약해줘:\n",
        "{text}\n",
        "\"\"\")\n",
        "summarize_chain = summarize_prompt | llm | parser\n",
        "\n",
        "# 2. 감정 분석 프롬프트\n",
        "sentiment_prompt = PromptTemplate.from_template(\"\"\"\n",
        "다음 글의 감정을 분석해줘. 감정은 긍정, 부정, 중립 중 하나로 답변해:\n",
        "{text}\n",
        "\"\"\")\n",
        "sentiment_chain = sentiment_prompt | llm | parser\n",
        "\n",
        "# 3. 요약 → 감정 분석 입력으로 활용하도록 병렬 처리 체인 구성\n",
        "summary_and_sentiment_chain = summarize_chain | RunnableParallel({\n",
        "    \"summary\": lambda summary: summary,  # 그냥 넘김\n",
        "    \"sentiment\": lambda summary: sentiment_chain.invoke({\"text\": summary})\n",
        "})\n",
        "\n",
        "# 4. 실행 예시\n",
        "text = \"\"\"\n",
        "오늘 시험에서 만점을 받았다. \n",
        "시험 준비를 열심히 해서 결과가 좋았다.\n",
        "시험이 끝난 후 친구들과 함께 축하 파티를 열었다.\n",
        "시험 준비를 하면서 힘든 순간도 있었지만,\n",
        "그런 순간들이 나를 더 강하게 만들어 주었다.\n",
        "정말 기쁘고 노력한 보람이 있었다!\n",
        "\"\"\"\n",
        "\n",
        "result = summary_and_sentiment_chain.invoke(text)\n",
        "\n",
        "print(\"📌 최종 결과:\")\n",
        "print(f\"요약: {result['summary']}\")\n",
        "print(f\"감정: {result['sentiment']}\")\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_openai import ChatOpenAI\n",
        "from operator import itemgetter\n",
        "\n",
        "# LLM과 출력 파서\n",
        "llm = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 1. 요약 프롬프트\n",
        "summarize_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "다음 글을 한 문장으로 요약해줘:\n",
        "{text}\n",
        "\"\"\")\n",
        "summarize_chain = summarize_prompt | llm | output_parser\n",
        "\n",
        "# 2. 감정 분석 프롬프트\n",
        "sentiment_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "다음 글의 감정을 분석해줘. 감정은 긍정, 부정, 중립 중 하나로 답변해:\n",
        "{text}\n",
        "\"\"\")\n",
        "sentiment_chain = sentiment_prompt | llm | output_parser\n",
        "\n",
        "# 3. 최종 응답 프롬프트\n",
        "final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "다음은 입력된 텍스트에 대한 분석 결과입니다:\n",
        "\n",
        "요약: {summary}\n",
        "감정: {sentiment}\n",
        "\n",
        "분석을 기반으로 독자에게 전달하고 싶은 핵심 메시지를 한 문장으로 정리해주세요.\n",
        "\"\"\")\n",
        "\n",
        "# 4. 병렬 처리 체인 구성\n",
        "analyze_chain = RunnableParallel({\n",
        "    \"summary\": summarize_chain,\n",
        "    \"sentiment\": sentiment_chain,\n",
        "    \"text\": itemgetter(\"text\")\n",
        "}) | final_prompt | llm | output_parser\n",
        "\n",
        "# 5. 실행 예시\n",
        "input_text = {\n",
        "    \"text\": \"\"\"\n",
        "오늘 시험에서 만점을 받았다. \n",
        "시험 준비를 열심히 해서 결과가 좋았다.\n",
        "시험이 끝난 후 친구들과 함께 축하 파티를 열었다.\n",
        "시험이 끝나고 나니 마음이 홀가분하다.\n",
        "정말 기쁘고 노력한 보람이 있었다!\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "result = analyze_chain.invoke(input_text)\n",
        "\n",
        "print(\"📌 최종 메시지:\")\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "faq_bot-1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
